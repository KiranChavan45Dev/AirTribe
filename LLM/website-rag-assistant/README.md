
# Website RAG Assistant

A **Retrieval-Augmented Generation (RAG)** based Q&A support bot that answers questions **only using content crawled from a given website**.

This project demonstrates the complete RAG workflow:
**web crawling â†’ text cleaning â†’ chunking â†’ embeddings â†’ vector storage â†’ retrieval â†’ grounded answer generation â†’ API endpoint**.

---

## ğŸš€ Features

* Crawls and indexes website content automatically
* Token-aware text chunking with overlap
* Semantic search using FAISS vector database
* OpenAI embeddings and LLM for answer generation
* Strict grounding: answers are generated **only from retrieved context**
* REST API for querying the assistant

---

## ğŸ—ï¸ Architecture Overview

```
Website URLs
   â†“
Web Scraper (BeautifulSoup)
   â†“
Text Cleaning
   â†“
Token-based Chunking
   â†“
OpenAI Embeddings
   â†“
FAISS Vector Store
   â†“
Similarity Retrieval
   â†“
LLM (RAG Prompt)
   â†“
Answer API (/ask)
```

---

## ğŸ“ Project Structure

```
app/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ routes.py            # API endpoints
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ llm_client.py        # OpenAI LLM wrapper
â”‚   â”œâ”€â”€ prompt_templates.py # System prompts
â”‚   â””â”€â”€ token_utils.py      # Token counting utilities
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ web_scraper.py      # Website crawling & scraping
â”‚   â””â”€â”€ chunker.py          # Token-based chunking
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ index_builder.py    # Index creation & persistence
â”‚   â””â”€â”€ qa_service.py       # Retrieval + generation logic
â”œâ”€â”€ vectorstore/
â”‚   â”œâ”€â”€ embeddings.py       # Embedding generation
â”‚   â””â”€â”€ faiss_index.py      # FAISS wrapper
â”œâ”€â”€ config.py               # Environment configuration
â””â”€â”€ main.py                 # Application entry point
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <repo-url>
cd website-rag-assistant
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Environment Variables

Create a `.env` file:

```env
OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL=gpt-4.1-mini
EMBEDDING_MODEL=text-embedding-3-small
```

---

## ğŸŒ Website Ingestion

Edit the base URLs in `main.py`:

```python
urls = [
    # freeCodeCamp
    "https://www.freecodecamp.org",
    "https://www.freecodecamp.org/news/",

    # Khan Academy
    "https://www.khanacademy.org/about",
    "https://www.khanacademy.org/math",

    # MIT OpenCourseWare
    "https://ocw.mit.edu",
    "https://ocw.mit.edu/about/",
]
```

On first startup, the application will:

1. Crawl the websites
2. Clean and chunk text
3. Generate embeddings
4. Build and persist a FAISS index

Subsequent startups reuse the saved index.

---

## â–¶ï¸ Running the Application

```bash
python app/main.py
```

The server starts at:

```
http://127.0.0.1:5000
```

---

## ğŸ” API Usage

### Endpoint

```
POST /ask
```

### Request Body

```json
{
  "question": "What is this website about?"
}
```

### Response

```json
{
  "answer": "..."
}
```

If the answer is not present in the crawled content:

```json
{
  "answer": "I don't know based on the provided information."
}
```

---

## ğŸ§ª Example Test Questions (with `curl`)

> Assumes Flask app runs at `http://127.0.0.1:5000/ask`

### ğŸŸ¢ freeCodeCamp

```bash
# What is freeCodeCamp?
curl -X POST http://127.0.0.1:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What is freeCodeCamp?"}'

# What subjects does freeCodeCamp teach?
curl -X POST http://127.0.0.1:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What subjects does freeCodeCamp teach?"}'

# Does freeCodeCamp provide certifications?
curl -X POST http://127.0.0.1:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Does freeCodeCamp provide certifications?"}'

# Negative test
curl -X POST http://127.0.0.1:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Does freeCodeCamp offer live 1-on-1 mentorship?"}'
```

### ğŸŸ¢ Khan Academy

```bash
# What subjects does Khan Academy teach?
curl -X POST http://127.0.0.1:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What subjects does Khan Academy teach?"}'

# Is Khan Academy free to use?
curl -X POST http://127.0.0.1:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Is Khan Academy free to use?"}'

# Who is the platform designed for?
curl -X POST http://127.0.0.1:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Who is the platform designed for?"}'

# Negative test
curl -X POST http://127.0.0.1:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Does Khan Academy offer paid in-person classes?"}'
```

### ğŸŸ¢ MIT OpenCourseWare

```bash
# What is MIT OpenCourseWare?
curl -X POST http://127.0.0.1:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What is MIT OpenCourseWare?"}'

# What materials are provided?
curl -X POST http://127.0.0.1:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What materials are provided by MIT OpenCourseWare?"}'

# Are certificates mentioned?
curl -X POST http://127.0.0.1:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Does MIT OpenCourseWare provide certificates?"}'

# Negative test
curl -X POST http://127.0.0.1:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Does MIT OpenCourseWare offer live tutoring?"}'
```

---

## ğŸ”® Possible Improvements

* Add source citations in API response
* Improve boilerplate removal during scraping
* Add async crawling for large sites
* Build a frontend chat UI
* Separate ingestion into a standalone CLI script

---
